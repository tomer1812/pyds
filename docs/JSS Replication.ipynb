{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bb569e98",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Replication Notebook for JSS paper\n",
    "### Estimated total running time: 2 hours and 15 minutes (Apple MacBook Pro M1 32Gb RAM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03172839",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# EventTimesSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bcf2bc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "nb_start = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15107aa0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pydts.data_generation import EventTimesSampler\n",
    "from pydts.examples_utils.plots import add_panel_text\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6437884d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ets = EventTimesSampler(d_times=7, j_event_types=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ed517b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_observations = 10000\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4081d847",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "observations_df = pd.DataFrame(columns=['Z1', 'Z2', 'Z3'])\n",
    "observations_df['Z1'] = np.random.binomial(n=1, p=0.5, size=n_observations)\n",
    "observations_df.loc[observations_df.loc[observations_df['Z1'] == 0].index, 'Z2'] = \\\n",
    "    np.random.normal(loc=72, scale=12, size=n_observations-observations_df['Z1'].sum())\n",
    "observations_df.loc[observations_df.loc[observations_df['Z1'] == 1].index, 'Z2'] = \\\n",
    "    np.random.normal(loc=82, scale=12, size=observations_df['Z1'].sum())\n",
    "observations_df['Z3'] = 1 + np.random.poisson(lam=4, size=n_observations)\n",
    "observations_df.astype(float).round(2).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b1ace0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(observations_df.astype(float).round(2).head().to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08c4c69",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fontsize=17\n",
    "fig, axes = plt.subplots(1,3, figsize=(16, 4))\n",
    "ax = axes[0]\n",
    "ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=15)\n",
    "add_panel_text(ax=ax, text='a')\n",
    "ax.bar(observations_df['Z1'].value_counts().index, observations_df['Z1'].value_counts().values, width=0.4)\n",
    "ax.set_xlabel('Z1', fontsize=fontsize)\n",
    "ax.set_ylabel('Number of observations', fontsize=fontsize)\n",
    "\n",
    "ax = axes[1]\n",
    "ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=15)\n",
    "add_panel_text(ax=ax, text='b')\n",
    "ax.hist(observations_df[observations_df['Z1'] == 0]['Z2'], bins=np.arange(30, 130, step=2), color='tab:orange', \n",
    "        label=r'$Z_1=0$', alpha=0.4)\n",
    "ax.hist(observations_df[observations_df['Z1'] == 1]['Z2'], bins=np.arange(30, 130, step=2), color='tab:green', \n",
    "        label=r'$Z_1=1$', alpha=0.4)\n",
    "ax.legend(fontsize=16)\n",
    "ax.set_xlabel('Z2', fontsize=fontsize)\n",
    "ax.set_ylabel('Number of observations', fontsize=fontsize)\n",
    "\n",
    "ax = axes[2]\n",
    "ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=15)\n",
    "add_panel_text(ax=ax, text='c')\n",
    "ax.bar(observations_df['Z3'].value_counts().index, observations_df['Z3'].value_counts().values, width=0.4)\n",
    "ax.set_xlabel('Z3', fontsize=fontsize)\n",
    "ax.set_ylabel('Number of observations', fontsize=fontsize)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598962f8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prob_lof_at_t = [0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05]\n",
    "observations_df = ets.sample_independent_lof_censoring(observations_df, prob_lof_at_t)\n",
    "observations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fae3d7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ets = EventTimesSampler(d_times=7, j_event_types=2)\n",
    "censoring_coef_dict = {\n",
    "    \"alpha\": {\n",
    "        0: lambda t: -0.3 - 0.3 * np.log(t),\n",
    "    },\n",
    "    \"beta\": {\n",
    "        0: -np.log([8, 0.95, 6]),\n",
    "    }\n",
    "}\n",
    "\n",
    "observations_df = ets.sample_hazard_lof_censoring(observations_df, censoring_coef_dict)\n",
    "observations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8b6619",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "observations_df['C'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9ff604",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "coefficients_dict = {\n",
    "    \"alpha\": {\n",
    "        1: lambda t: -1 - 0.3 * np.log(t),\n",
    "        2: lambda t: -1.75 - 0.15 * np.log(t)\n",
    "    },\n",
    "    \"beta\": {\n",
    "        1: -np.log([0.8, 1.4, 3]),\n",
    "        2: -np.log([1, 0.95, 2])\n",
    "    }\n",
    "}\n",
    "observations_df = ets.sample_event_times(observations_df, coefficients_dict)\n",
    "observations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb701d8a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "observations_df['T'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55988ca",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "observations_df['J'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321d5d98",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "observations_df = ets.update_event_or_lof(observations_df)\n",
    "tmp = observations_df.astype({'Z1': int, 'Z2': float, 'Z3': int, 'X': int, \n",
    "                        'C': int, 'J': int, 'T': int}).round(2).head()[['Z1', 'Z2', 'Z3', 'T', 'C', 'X', 'J']]\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6762725",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(tmp.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bd0146",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Simulation Study - Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a48743",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "For simplicity of presentation, we considered $M=2$ competing events, though PyDTS can handle any number of competing events as long as there are enough observed failures of each failure type, at each discrete time point.\n",
    "\n",
    "Here, $d=30$ discrete time points, $n=50,000$ observations, and $Z$ with 5 covariates. Failure times of observations were generated based on the model:\n",
    "\n",
    "$$\n",
    "\\lambda_{j}(t|Z) = \\frac{\\exp(\\alpha_{jt}+Z^{T}\\beta_{j})}{1+\\exp(\\alpha_{jt}+Z^{T}\\beta_{j})}\n",
    "$$\n",
    "\n",
    "with \n",
    "\n",
    "$\\alpha_{1t} = -1 -0.3 \\log(t)$, \n",
    "\n",
    "$\\alpha_{2t} = -1.75 -0.15\\log(t)$, $t=1,\\ldots,d$,\n",
    "\n",
    "$\\beta_1 = (-\\log 0.8, \\log 3, \\log 3, \\log 2.5, \\log 2)$, \n",
    "\n",
    "$\\beta_{2} = (-\\log 1, \\log 3, \\log 4, \\log 3, \\log 2)$. \n",
    "\n",
    "Censoring time for each observation was sampled from a discrete uniform distribution, i.e. $C_i \\sim \\mbox{Uniform}\\{1,...,d+1\\}$.\n",
    "\n",
    "Our goal is estimating $\\{\\alpha_{11},\\ldots,\\alpha_{1d},\\beta_1^T,\\alpha_{21},\\ldots,\\alpha_{2d},\\beta_2^T\\}$ (70 parameters in total) along with the standard error of the estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5491805b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pydts.examples_utils.generate_simulations_data import generate_quick_start_df\n",
    "import warnings\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b57ce9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "real_coef_dict = {\n",
    "    \"alpha\": {\n",
    "        1: lambda t: -1 - 0.3 * np.log(t),\n",
    "        2: lambda t: -1.75 - 0.15 * np.log(t)\n",
    "    },\n",
    "    \"beta\": {\n",
    "        1: -np.log([0.8, 3, 3, 2.5, 2]),\n",
    "        2: -np.log([1, 3, 4, 3, 2])\n",
    "    }\n",
    "}\n",
    "\n",
    "n_patients = 50000\n",
    "n_cov = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6253079",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "patients_df = generate_quick_start_df(n_patients=n_patients, n_cov=n_cov, d_times=30, j_events=2, \n",
    "                                      pid_col='pid', seed=0, censoring_prob=0.8, \n",
    "                                      real_coef_dict=real_coef_dict)\n",
    "\n",
    "patients_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea392eb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Checking the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5485495",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Both estimation methods require enough observed failures of each failure type, at each discrete time point. Therefore, the first step is to make sure this is in fact the case with the data at hand.\n",
    "\n",
    "As shown below, in our example, the data comply with this requirement. \n",
    "\n",
    "Preprocessing suggestions for cases when the data do not comply with this requirement are shown in Data Regrouping Example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafb65e8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pydts.examples_utils.plots import plot_events_occurrence\n",
    "plot_events_occurrence(patients_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228f480d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "patients_df.groupby(['J', 'X'])['pid'].count().unstack('J')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980f1ae3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Estimating with DataExpansionFitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e46a3da",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pydts.examples_utils.generate_simulations_data import generate_quick_start_df\n",
    "import warnings\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199169d2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "real_coef_dict = {\n",
    "    \"alpha\": {\n",
    "        1: lambda t: -1 - 0.3 * np.log(t),\n",
    "        2: lambda t: -1.75 - 0.15 * np.log(t)\n",
    "    },\n",
    "    \"beta\": {\n",
    "        1: -np.log([0.8, 3, 3, 2.5, 2]),\n",
    "        2: -np.log([1, 3, 4, 3, 2])\n",
    "    }\n",
    "}\n",
    "\n",
    "n_patients = 50000\n",
    "n_cov = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35a81ca",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "patients_df = generate_quick_start_df(n_patients=n_patients, n_cov=n_cov, d_times=30, j_events=2, \n",
    "                                      pid_col='pid', seed=0, censoring_prob=0.8, \n",
    "                                      real_coef_dict=real_coef_dict)\n",
    "patients_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82833492",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14d15de",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In the following we apply the estimation method of Lee et al. (2018). Note that the data dataframe must not contain a column named 'C'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7c6bf9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pydts.fitters import DataExpansionFitter\n",
    "fitter = DataExpansionFitter()\n",
    "fitter.fit(df=patients_df.drop(['C', 'T'], axis=1))\n",
    "\n",
    "fitter.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192c6f8a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pydts.examples_utils.plots import plot_first_model_coefs\n",
    "plot_first_model_coefs(models=fitter.event_models, times=fitter.times, train_df=patients_df, n_cov=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4b2c2f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "summary = fitter.event_models[1].summary()\n",
    "summary_df = pd.DataFrame([x.split(',') for x in summary.tables[1].as_csv().split('\\n')])\n",
    "summary_df.columns = summary_df.iloc[0]\n",
    "summary_df = summary_df.iloc[1:].set_index(summary_df.columns[0])\n",
    "lee_beta1_summary = summary_df.iloc[-5:]\n",
    "lee_beta1_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490b07df",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "summary = fitter.event_models[2].summary()\n",
    "summary_df = pd.DataFrame([x.split(',') for x in summary.tables[1].as_csv().split('\\n')])\n",
    "summary_df.columns = summary_df.iloc[0]\n",
    "summary_df = summary_df.iloc[1:].set_index(summary_df.columns[0])\n",
    "lee_beta2_summary = summary_df.iloc[-5:]\n",
    "lee_beta2_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6696edc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Full prediction is given by the method predict_cumulative_incident_function()\n",
    "\n",
    "The input is a pandas.DataFrame() containing for each observation the covariates columns which were used in the fit() method (Z1-Z5 in our example).\n",
    "\n",
    "The following columns will be added:\n",
    "\n",
    "1. The overall survival at each time point t\n",
    "2. The hazard for each failure type $j$ at each time point t\n",
    "3. The probability of event type $j$ at time t\n",
    "4. The Cumulative Incident Function (CIF) of event type $j$ at time t\n",
    "\n",
    "In the following, we provide predictions for the individuals with ID values (pid) 0, 1 and 2. We transposed the output for easy view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8665f2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pred_df = fitter.predict_cumulative_incident_function(\n",
    "    patients_df.drop(['J', 'T', 'C', 'X'], axis=1).head(3)).set_index('pid').T\n",
    "pred_df.index.name = ''\n",
    "pred_df.columns = ['ID=0', 'ID=1', 'ID=2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6e0855",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pydts.examples_utils.plots import plot_example_pred_output\n",
    "plot_example_pred_output(pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e04686",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(pred_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7c280a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Estimating with TwoStagesFitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec762e32",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pydts.examples_utils.generate_simulations_data import generate_quick_start_df\n",
    "import warnings\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e18060",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "real_coef_dict = {\n",
    "    \"alpha\": {\n",
    "        1: lambda t: -1 - 0.3 * np.log(t),\n",
    "        2: lambda t: -1.75 - 0.15 * np.log(t)\n",
    "    },\n",
    "    \"beta\": {\n",
    "        1: -np.log([0.8, 3, 3, 2.5, 2]),\n",
    "        2: -np.log([1, 3, 4, 3, 2])\n",
    "    }\n",
    "}\n",
    "\n",
    "n_patients = 50000\n",
    "n_cov = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e85cfb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "patients_df = generate_quick_start_df(n_patients=n_patients, n_cov=n_cov, d_times=30, j_events=2, \n",
    "                                      pid_col='pid', seed=0, censoring_prob=0.8, \n",
    "                                      real_coef_dict=real_coef_dict)\n",
    "patients_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211216a6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88180f8b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In the following we apply the estimation method of Meir et al. (2022). Note that the data dataframe must not contain a column named 'C'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392b5e8c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pydts.fitters import TwoStagesFitter\n",
    "new_fitter = TwoStagesFitter()\n",
    "new_fitter.fit(df=patients_df.drop(['C', 'T'], axis=1))\n",
    "\n",
    "new_fitter.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6e98be",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pydts.examples_utils.plots import plot_second_model_coefs\n",
    "plot_second_model_coefs(new_fitter.alpha_df, new_fitter.beta_models, new_fitter.times, n_cov=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e5b7f9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Standard Error of the Regression Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305dfc98",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(new_fitter.get_beta_SE())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a50189",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "new_fitter.plot_all_events_alpha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c7e715",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "new_fitter.plot_all_events_beta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed82a438",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "twostep_beta_summary = new_fitter.get_beta_SE()\n",
    "twostep_beta1_summary = twostep_beta_summary.iloc[:,[0,1]]\n",
    "twostep_beta2_summary = twostep_beta_summary.iloc[:,[2,3]]\n",
    "twostep_beta_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a783b135",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Standard Error of the Regression Coefficients Comparison Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0560c687",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lee_beta1_summary.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25755f0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lee_beta1_summary = lee_beta1_summary.iloc[:, [0,1]].round(3)\n",
    "lee_beta2_summary = lee_beta2_summary.iloc[:, [0,1]].round(3)\n",
    "lee_beta1_summary.columns = pd.MultiIndex.from_tuples([('Lee et al.', 'Estimate'), ('Lee et al.', 'SE')])\n",
    "lee_beta2_summary.columns = pd.MultiIndex.from_tuples([('Lee et al.', 'Estimate'), ('Lee et al.', 'SE')])\n",
    "beta_summary_comparison = pd.concat([lee_beta1_summary, lee_beta2_summary], axis=0)\n",
    "beta_summary_comparison.index = [r'$\\beta_{11}$', r'$\\beta_{12}$', r'$\\beta_{13}$', r'$\\beta_{14}$', r'$\\beta_{15}$',\n",
    "                                 r'$\\beta_{21}$', r'$\\beta_{22}$', r'$\\beta_{23}$', r'$\\beta_{24}$', r'$\\beta_{25}$']\n",
    "twostep_beta1_summary.columns = pd.MultiIndex.from_tuples([('two-step', 'Estimate'), ('two-step', 'SE')])\n",
    "twostep_beta2_summary.columns = pd.MultiIndex.from_tuples([('two-step', 'Estimate'), ('two-step', 'SE')])\n",
    "tmp = pd.concat([twostep_beta1_summary.round(3), twostep_beta2_summary.round(3)], axis=0)\n",
    "tmp.index = [r'$\\beta_{11}$', r'$\\beta_{12}$', r'$\\beta_{13}$', r'$\\beta_{14}$', r'$\\beta_{15}$',\n",
    "             r'$\\beta_{21}$', r'$\\beta_{22}$', r'$\\beta_{23}$', r'$\\beta_{24}$', r'$\\beta_{25}$']\n",
    "beta_summary_comparison = pd.concat([beta_summary_comparison, tmp], axis=1)\n",
    "beta_summary_comparison.index.name =  r'$\\beta_{jk}$'\n",
    "\n",
    "true_col = -np.log([0.8, 3, 3, 2.5, 2, 1, 3, 4, 3, 2])   \n",
    "beta_summary_comparison.insert(loc=0, column='True', value=true_col)\n",
    "beta_summary_comparison.astype(float).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47871828",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(beta_summary_comparison.astype(float).round(3).to_latex(escape=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6a4563",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a45bac",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "It is possible to add regularization when estimating the Beta coefficients. It is done by using the CoxPHFitter (Lifelines) penalizer and l1_ratio arguments, which can be passed using the fit_beta_kwargs argument to the fit() method. The added regularization term is of the form:\n",
    "$$\n",
    "\\mbox{Penalizer} \\cdot \\Bigg( \\frac{1-\\mbox{L1_ratio}}{2}||\\beta||_{2}^{2} + \\mbox{L1_ratio} ||\\beta||_1 \\Bigg)\n",
    "$$\n",
    "Examples for adding L1, L2 and Elastic Net regularization are followed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e39ae5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30555d1a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "L1_regularized_fitter = TwoStagesFitter()\n",
    "\n",
    "fit_beta_kwargs = {\n",
    "    'model_kwargs': {\n",
    "        1: {'penalizer': 0.003, 'l1_ratio': 1},\n",
    "        2: {'penalizer': 0.005, 'l1_ratio': 1}\n",
    "}}\n",
    "\n",
    "L1_regularized_fitter.fit(df=patients_df.drop(['C', 'T'], axis=1), fit_beta_kwargs=fit_beta_kwargs)\n",
    "\n",
    "L1_regularized_fitter.get_beta_SE()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d7ccbf",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0c1250",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "L2_regularized_fitter = TwoStagesFitter()\n",
    "\n",
    "fit_beta_kwargs = {\n",
    "    'model_kwargs': {\n",
    "        1: {'penalizer': 0.003, 'l1_ratio': 0},\n",
    "        2: {'penalizer': 0.005, 'l1_ratio': 0}\n",
    "}}\n",
    "\n",
    "L2_regularized_fitter.fit(df=patients_df.drop(['C', 'T'], axis=1), fit_beta_kwargs=fit_beta_kwargs)\n",
    "\n",
    "L2_regularized_fitter.get_beta_SE()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af23fce9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389bb492",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "EN_regularized_fitter = TwoStagesFitter()\n",
    "\n",
    "fit_beta_kwargs = {\n",
    "    'model_kwargs': {\n",
    "        1: {'penalizer': 0.003, 'l1_ratio': 0.5},\n",
    "        2: {'penalizer': 0.005, 'l1_ratio': 0.5}\n",
    "}}\n",
    "\n",
    "EN_regularized_fitter.fit(df=patients_df.drop(['C', 'T'], axis=1), fit_beta_kwargs=fit_beta_kwargs)\n",
    "\n",
    "EN_regularized_fitter.get_beta_SE()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e11c31d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Separated Penalty Coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a906ffc1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The above methods can be applied with a separate penalty coefficient to each of the covariates by passing a vector (with same length as the number of covariates) to the penalizer keyword instead of a scalar. For example, applying L2 regularization only to covariates Z1, Z2 can be done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e29bc23",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "L2_regularized_fitter = TwoStagesFitter()\n",
    "\n",
    "fit_beta_kwargs = {\n",
    "    'model_kwargs': {\n",
    "        1: {'penalizer': np.array([0.01, 0.01, 0.01, 0.01, 0]), 'l1_ratio': 0},\n",
    "        2: {'penalizer': np.array([0.05, 0.05, 0.05, 0.05, 0]), 'l1_ratio': 0}\n",
    "}}\n",
    "\n",
    "L2_regularized_fitter.fit(df=patients_df.drop(['C', 'T'], axis=1), fit_beta_kwargs=fit_beta_kwargs)\n",
    "\n",
    "L2_regularized_fitter.get_beta_SE()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50428c45",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0dd398",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Full prediction is given by the method predict_cumulative_incident_function()\n",
    "\n",
    "The input is a pandas.DataFrame() containing for each observation the covariates columns which were used in the fit() method (Z1-Z5 in our example).\n",
    "\n",
    "The following columns will be added:\n",
    "\n",
    "1. The overall survival at each time point t\n",
    "2. The hazard for each failure type $j$ at each time point t\n",
    "3. The probability of event type $j$ at time t\n",
    "4. The Cumulative Incident Function (CIF) of event type $j$ at time t\n",
    "\n",
    "In the following, we provide predictions for the individuals with ID values (pid) 0, 1 and 2. We transposed the output for easy view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4636766",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pred_df = new_fitter.predict_cumulative_incident_function(\n",
    "    patients_df.drop(['J', 'T', 'C', 'X'], axis=1).head(3)).set_index('pid').T\n",
    "pred_df.index.name = ''\n",
    "pred_df.columns = ['ID=0', 'ID=1', 'ID=2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a84caff",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pydts.examples_utils.plots import plot_example_pred_output\n",
    "plot_example_pred_output(pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad89c5d2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5d9b19",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Comparing the Estimation Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5736c29",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c791b1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We conducted a simulation study demonstrating the performances of Meir et al. (2022) [1] and comparing it with that of Lee et al. (2018) [2]. \n",
    "\n",
    "The data was generated in the same way as in Usage Example section, i.e. $M=2$ competing events, $n=50,000$ observations, Z with 5 covariates and right censoring. \n",
    "\n",
    "Failure times were generated based on \n",
    "\n",
    "$$\n",
    "\\lambda_{j}(t|Z) = \\frac{\\exp(\\alpha_{jt}+Z^{T}\\beta_{j})}{1+\\exp(\\alpha_{jt}+Z^{T}\\beta_{j})}\n",
    "$$\n",
    "\n",
    "with \n",
    "\n",
    "$\\alpha_{1t} = -1 -0.3 \\log(t)$, \n",
    "\n",
    "$\\alpha_{2t} = -1.75 -0.15\\log(t)$, $t=1,\\ldots,d$,\n",
    "\n",
    "$\\beta_1 = (-\\log 0.8, \\log 3, \\log 3, \\log 2.5, \\log 2)$, \n",
    "\n",
    "$\\beta_{2} = (-\\log 1, \\log 3, \\log 4, \\log 3, \\log 2)$. \n",
    "\n",
    "Censoring time for each observation was sampled from a discrete uniform distribution, i.e. $C_i \\sim \\mbox{Uniform}\\{1,...,d+1\\}$. \n",
    "\n",
    "We repeated this procedure for $d \\in (15, 30, 45, 60, 100)$ and report the results in Meir et al. (2022) [1]. For each value of $d$, the results are based on 100 replications. \n",
    "\n",
    "We showed that both estimation methods perform very well in terms of bias and provide highly similar results in terms of point estimators and their standard errors. However, the computational running time of our approach is 1.5-3.5 times shorter depending on $d$, where the improvement factor increases as a function of $d$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfa486f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Estimation Replications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b933b3de",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pydts.examples_utils.generate_simulations_data import generate_quick_start_df\n",
    "import warnings\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a4b367",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "real_coef_dict = {\n",
    "    \"alpha\": {\n",
    "        1: lambda t: -1 - 0.3 * np.log(t),\n",
    "        2: lambda t: -1.75 - 0.15 * np.log(t)\n",
    "    },\n",
    "    \"beta\": {\n",
    "        1: -np.log([0.8, 3, 3, 2.5, 2]),\n",
    "        2: -np.log([1, 3, 4, 3, 2])\n",
    "    }\n",
    "}\n",
    "\n",
    "n_patients = 50000\n",
    "n_cov = 5\n",
    "\n",
    "\n",
    "# In JSS paper the results of 100 replications are presented.\n",
    "# We present the results here for 5 replication for reasonable running time.\n",
    "# For higher number of d_times, longer running time is expected.\n",
    "# Estimated running time for each replication when d=30: 45 seconds\n",
    "\n",
    "replications = 5  \n",
    "d_times = 30 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e7ab7a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pydts.fitters import repetitive_fitters\n",
    "rep_dict, times_dict, counts_df = repetitive_fitters(rep=replications, n_patients=n_patients, n_cov=n_cov, \n",
    "                                                     d_times=30, j_events=2, pid_col='pid', test_size=0.25, \n",
    "                                                     verbose=0, real_coef_dict=real_coef_dict, censoring_prob=0.8,\n",
    "                                                     allow_fails=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d85ee6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Comparing Standard Error of Lee et al. (2018) and Meir et al. (2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87724570",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pydts.examples_utils.plots import plot_reps_coef_std\n",
    "\n",
    "new_res_dict = plot_reps_coef_std(rep_dict, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804085fa",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Comparison of the Estimated Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85736cc4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pydts.examples_utils.plots import plot_models_coefficients\n",
    "a = new_res_dict['alpha']\n",
    "b = new_res_dict['beta']\n",
    "times = [t+1 for t in list(a[1].reset_index().index)]\n",
    "n_cov = 5\n",
    "plot_models_coefficients(a, b, times, counts_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651307f2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Computational Time Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b6319d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pydts.examples_utils.plots import plot_times\n",
    "\n",
    "plot_times(times_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7acbbaf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "beta_comparison_table = pd.DataFrame(index=['True', 'Mean (Lee et al.)', 'SE (Lee et al.)',\n",
    "                                              'Mean (two-step)', 'SE (two-step)'])\n",
    "for j in [1, 2]:\n",
    "    for i in range(1, 6):\n",
    "        tmp_df = pd.DataFrame()\n",
    "        for idx, k in enumerate(sorted(rep_dict.keys())):\n",
    "            lee = rep_dict[k]['beta'][j].loc[f\"Z{i}_{j}\"]['Lee']\n",
    "            ours = rep_dict[k]['beta'][j].loc[f\"Z{i}_{j}\"]['Ours']\n",
    "            true = rep_dict[k]['beta'][j].loc[f\"Z{i}_{j}\"]['real']\n",
    "            row = pd.Series({'True': true, 'Lee': lee, 'Ours': ours}, name=f\"Z{i}_{j}_{k}\")\n",
    "            tmp_df = pd.concat([tmp_df, row], axis=1)\n",
    "        beta_row = pd.Series({\n",
    "            'True': tmp_df.iloc[0,0],\n",
    "            'Mean (Lee et al.)': tmp_df.iloc[1].mean(), \n",
    "            'SE (Lee et al.)': tmp_df.iloc[1].std(),\n",
    "            'Mean (two-step)': tmp_df.iloc[2].mean(),\n",
    "            'SE (two-step)': tmp_df.iloc[2].std()\n",
    "        }, name=f'Z{i}_{j}')\n",
    "        beta_comparison_table = pd.concat([beta_comparison_table, beta_row], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873c9377",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "beta_comparison_table = beta_comparison_table.round(3).T\n",
    "beta_comparison_table.columns = pd.MultiIndex.from_tuples(\n",
    "    [('True', ''), ('Lee et al.', 'Estimate'), ('Lee et al.', 'SE'), ('two-step', 'Estimate'), ('two-step', 'SE')])\n",
    "beta_comparison_table.index = [r'$\\beta_{11}$', r'$\\beta_{12}$', r'$\\beta_{13}$', r'$\\beta_{14}$', r'$\\beta_{15}$',\n",
    "                               r'$\\beta_{21}$', r'$\\beta_{22}$', r'$\\beta_{23}$', r'$\\beta_{24}$', r'$\\beta_{25}$']\n",
    "beta_comparison_table.index.name = r'$\\beta_{jk}$'\n",
    "beta_comparison_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1c5ecc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(beta_comparison_table.to_latex(escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b294f9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pydts.examples_utils.plots import plot_reps_coef_std\n",
    "\n",
    "new_res_dict = plot_reps_coef_std(rep_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "67f69109",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Penalty Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89289918",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from pydts.model_selection import PenaltyGridSearch\n",
    "from pydts.cross_validation import PenaltyGridSearchCV\n",
    "train_df, test_df = train_test_split(patients_df, train_size=0.8, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6a28e3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "penalizers = np.exp([-2, -3, -4, -5, -6])\n",
    "grid_search = PenaltyGridSearch()\n",
    "optimal_set = grid_search.evaluate(train_df, test_df, l1_ratio=1, \n",
    "                                   penalizers=penalizers,\n",
    "                                   metrics=['IBS', 'GBS', 'IAUC', 'GAUC']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09b4e92",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(np.log(optimal_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1d83b8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(np.log(grid_search.convert_results_dict_to_df(grid_search.global_bs).idxmin().values[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10983efe",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "penalizers = np.exp([-2, -3, -4, -5, -6])\n",
    "grid_search_cv = PenaltyGridSearchCV()\n",
    "results_df = grid_search_cv.cross_validate(patients_df, l1_ratio=1, \n",
    "                                penalizers=penalizers, n_splits=5, \n",
    "                                metrics=['IBS', 'GBS', 'IAUC', 'GAUC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09e5a3a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results_df['Mean'].idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4092a4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results_df_ = results_df.copy().reset_index()\n",
    "results_df_.iloc[:, :2] = np.log(results_df_.iloc[:, :2])\n",
    "results_df_ = results_df_.set_index(['level_0','level_1'])\n",
    "results_df_.index.set_names(['log(eta_1)', 'log(eta_2)'], inplace=True)\n",
    "print(results_df_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5e15ce",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nb_end = time()\n",
    "print(int(nb_end-nb_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc2577a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## References\n",
    "\n",
    "[1] Meir, Tomer\\*, Gutman, Rom\\*, and Gorfine, Malka, \"PyDTS: A Python Package for Discrete-Time Survival Analysis with Competing Risks\" (2022)\n",
    "\n",
    "[2] Lee, Minjung and Feuer, Eric J. and Fine, Jason P., \"On the analysis of discrete time competing risks data\", Biometrics (2018) doi: 10.1111/biom.12881"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}